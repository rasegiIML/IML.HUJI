{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize estimator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import NoReturn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import RocCurveDisplay, accuracy_score\n",
    "\n",
    "from IMLearn.base import BaseEstimator\n",
    "\n",
    "import re\n",
    "from copy import copy\n",
    "from datetime import datetime\n",
    "from typing import NoReturn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from IMLearn import BaseEstimator\n",
    "from challenge.agoda_cancellation_estimator import AgodaCancellationEstimator\n",
    "\n",
    "\n",
    "\n",
    "class AgodaCancellationEstimator(BaseEstimator):\n",
    "    def __init__(self, threshold: float = None) -> AgodaCancellationEstimator:\n",
    "        super().__init__()\n",
    "        self.__fit_model: RandomForestClassifier = None\n",
    "        self.thresh = threshold\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        return {'threshold': self.thresh}\n",
    "\n",
    "    def set_params(self, threshold) -> AgodaCancellationEstimator:\n",
    "        self.thresh = threshold\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _fit(self, X: np.ndarray, y: np.ndarray) -> NoReturn:\n",
    "        self.__fit_model = RandomForestClassifier(random_state=0).fit(X, y)\n",
    "\n",
    "    def _predict(self, X: pd.DataFrame) -> np.ndarray:\n",
    "        probs = self.__fit_model.predict_proba(X)[:, 1]\n",
    "        return np.logical_not(probs > self.thresh if self.thresh is not None else probs).astype('int')\n",
    "\n",
    "    def _loss(self, X: np.ndarray, y: np.ndarray) -> float:\n",
    "        pass\n",
    "\n",
    "    def plot_roc_curve(self, X: np.ndarray, y: np.ndarray):\n",
    "        RocCurveDisplay.from_estimator(self.__fit_model, X, y)\n",
    "\n",
    "    def score(self, X: pd.DataFrame, y: pd.Series):\n",
    "        return accuracy_score(y, self._predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def read_data_file(path: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(path).drop_duplicates() \\\n",
    "        .astype({'checkout_date': 'datetime64',\n",
    "                 'checkin_date': 'datetime64',\n",
    "                 'hotel_live_date': 'datetime64',\n",
    "                 'booking_datetime': 'datetime64'})\n",
    "\n",
    "\n",
    "def get_days_between_dates(dates1: pd.Series, dates2: pd.Series):\n",
    "    return (dates1 - dates2).apply(lambda period: period.days)\n",
    "\n",
    "\n",
    "def create_col_prob_mapper(col: str, mapper: dict):\n",
    "    mapper = copy(mapper)\n",
    "\n",
    "    def map_col_to_prob(df):\n",
    "        df[col] = df[col].apply(mapper.get)\n",
    "\n",
    "        return df\n",
    "\n",
    "    return map_col_to_prob\n",
    "\n",
    "\n",
    "def add_categorical_prep_to_pipe(train_features: pd.DataFrame, pipeline: Pipeline, cat_vars: list, one_hot=False,\n",
    "                                 calc_probs=True) -> Pipeline:\n",
    "    assert one_hot ^ calc_probs, \\\n",
    "        'Error: can only do either one-hot encoding or probability calculations, not neither/both!'\n",
    "    # one-hot encoding\n",
    "    if one_hot:\n",
    "        # TODO - use sklearn OneHotEncoder\n",
    "        pipeline.steps.append(('one-hot encoding',\n",
    "                               FunctionTransformer(lambda df: pd.get_dummies(df, columns=cat_vars))))\n",
    "\n",
    "    # category probability preprocessing - make each category have its success percentage\n",
    "    if calc_probs:\n",
    "        for cat_var in cat_vars:\n",
    "            map_cat_to_prob: dict = train_features.groupby(cat_var, dropna=False).labels.mean().to_dict()\n",
    "\n",
    "            pipeline.steps.append((f'map {cat_var} to prob',\n",
    "                                   FunctionTransformer(create_col_prob_mapper(cat_var, map_cat_to_prob))))\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def get_week_of_year(dates):\n",
    "    return dates.apply(lambda d: d.weekofyear)\n",
    "\n",
    "\n",
    "def get_booked_on_weekend(dates):\n",
    "    return dates.apply(lambda d: d.day_of_week >= 4)\n",
    "\n",
    "\n",
    "def get_weekend_holiday(in_date, out_date):\n",
    "    return list(map(lambda d: (d[1] - d[0]).days <= 3 and d[0].dayofweek >= 4, zip(in_date, out_date)))\n",
    "\n",
    "\n",
    "def get_local_holiday(col1, col2):\n",
    "    return list(map(lambda x: x[0] == x[1], zip(col1, col2)))\n",
    "\n",
    "\n",
    "def get_days_until_policy(policy_code: str) -> list:\n",
    "    policies = policy_code.split('_')\n",
    "    return [int(policy.split('D')[0]) if 'D' in policy else 0 for policy in policies]\n",
    "\n",
    "\n",
    "def get_policy_cost(policy, stay_cost, stay_length, time_until_checkin):\n",
    "    \"\"\"\n",
    "    returns tuple of the format (max lost, min lost, part min lost)\n",
    "    \"\"\"\n",
    "    if policy == 'UNKNOWN':\n",
    "        return 0, 0, 0\n",
    "    nums = tuple(map(int, re.split('[a-zA-Z]', policy)[:-1]))\n",
    "    if 'D' not in policy:  # no show is suppressed\n",
    "        return 0, 0, 0\n",
    "    if 'N' in policy:\n",
    "        nights_cost = stay_cost / stay_length * nums[0]\n",
    "        min_cost = nights_cost if time_until_checkin <= nums[1] else 0\n",
    "        return nights_cost, min_cost, min_cost / stay_cost\n",
    "    elif 'P' in policy:\n",
    "        nights_cost = stay_cost * nums[0] / 100\n",
    "        min_cost = nights_cost if time_until_checkin <= nums[1] else 0\n",
    "        return nights_cost, min_cost, min_cost / stay_cost\n",
    "    else:\n",
    "        raise Exception(\"Invalid Input\")\n",
    "\n",
    "\n",
    "def get_money_lost_per_policy(features: pd.Series) -> list:\n",
    "    policies = features.cancellation_policy_code.split('_')\n",
    "    stay_cost = features.original_selling_amount\n",
    "    stay_length = features.stay_length\n",
    "    time_until_checkin = features.booking_to_arrival_time\n",
    "    policy_cost = [get_policy_cost(policy, stay_cost, stay_length, time_until_checkin) for policy in policies]\n",
    "\n",
    "    return list(map(list, zip(*policy_cost)))\n",
    "\n",
    "\n",
    "def add_cancellation_policy_features(features: pd.DataFrame) -> pd.DataFrame:\n",
    "    cancellation_policy = features.cancellation_policy_code\n",
    "    features['n_policies'] = cancellation_policy.apply(lambda policy: len(policy.split('_')))\n",
    "    days_until_policy = cancellation_policy.apply(get_days_until_policy)\n",
    "\n",
    "    features['min_policy_days'] = days_until_policy.apply(min)\n",
    "    features['max_policy_days'] = days_until_policy.apply(max)\n",
    "\n",
    "    # x = features.apply(get_money_lost_per_policy, axis='columns')\n",
    "    # features['max_policy_cost'], features['min_policy_cost'], features['part_min_policy_cost'] = list(\n",
    "    #     map(list, zip(*x)))\n",
    "\n",
    "    # features['min_policy_cost'] = features['min_policy_cost'].apply(min)\n",
    "    # features['part_min_policy_cost'] = features['part_min_policy_cost'].apply(min)\n",
    "    # features['max_policy_cost'] = features['max_policy_cost'].apply(max)\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def add_time_based_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df['stay_length'] = get_days_between_dates(df.checkout_date, df.checkin_date)\n",
    "    df['time_registered_pre_book'] = get_days_between_dates(df.checkin_date, df.hotel_live_date)\n",
    "    df['booking_to_arrival_time'] = get_days_between_dates(df.checkin_date, df.booking_datetime)\n",
    "    df['checkin_week_of_year'] = get_week_of_year(df.checkin_date)\n",
    "    df['booking_week_of_year'] = get_week_of_year(df.booking_datetime)\n",
    "    df['booked_on_weekend'] = get_booked_on_weekend(df.booking_datetime)\n",
    "    df['is_weekend_holiday'] = get_weekend_holiday(df.checkin_date, df.checkout_date)\n",
    "    df['is_local_holiday'] = get_local_holiday(df.origin_country_code, df.hotel_country_code)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_pipeline_from_data(filename: str):\n",
    "    NONE_OUTPUT_COLUMNS = ['checkin_date',\n",
    "                           'checkout_date',\n",
    "                           'booking_datetime',\n",
    "                           'hotel_live_date',\n",
    "                           'hotel_country_code',\n",
    "                           'origin_country_code',\n",
    "                           'cancellation_policy_code']\n",
    "    CATEGORICAL_COLUMNS = ['hotel_star_rating',\n",
    "                           'guest_nationality_country_name',\n",
    "                           'charge_option',\n",
    "                           'accommadation_type_name',\n",
    "                           'language',\n",
    "                           'is_first_booking',\n",
    "                           'customer_nationality',\n",
    "                           'original_payment_currency',\n",
    "                           'is_user_logged_in',\n",
    "                           ]\n",
    "    RELEVANT_COLUMNS = ['no_of_adults',\n",
    "                        'no_of_children',\n",
    "                        'no_of_extra_bed',\n",
    "                        'no_of_room',\n",
    "                        'original_selling_amount'] + NONE_OUTPUT_COLUMNS + CATEGORICAL_COLUMNS\n",
    "    features = read_data_file(filename)\n",
    "\n",
    "    features['labels'] = features[\"cancellation_datetime\"].isna()\n",
    "\n",
    "    pipeline_steps = [('columns selector', FunctionTransformer(lambda df: df[RELEVANT_COLUMNS])),\n",
    "                      ('add time based columns', FunctionTransformer(add_time_based_cols)),\n",
    "                      ('add cancellation policy features', FunctionTransformer(add_cancellation_policy_features)),\n",
    "                      ('drop irrelevant columns',\n",
    "                       FunctionTransformer(lambda df: df.drop(NONE_OUTPUT_COLUMNS, axis='columns')))\n",
    "                      ]\n",
    "\n",
    "    pipeline = Pipeline(pipeline_steps)\n",
    "    pipeline = add_categorical_prep_to_pipe(features, pipeline, CATEGORICAL_COLUMNS)\n",
    "\n",
    "    return features.drop('labels', axis='columns'), features.labels, pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Train, predict and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_and_export(estimator: BaseEstimator, X: pd.DataFrame, filename: str):\n",
    "    preds = estimator.predict(X)\n",
    "    pd.DataFrame(preds, columns=[\"predicted_values\"]).to_csv(filename, index=False)\n",
    "\n",
    "\n",
    "def create_estimator_from_data(path=\"../datasets/agoda_cancellation_train.csv\", threshold: float = 0.47,\n",
    "                               optimize_threshold=False, debug=False) -> Pipeline:\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Load data\n",
    "    raw_df, cancellation_labels, pipeline = create_pipeline_from_data(path)\n",
    "\n",
    "    train_X = raw_df\n",
    "    train_y = cancellation_labels\n",
    "    train_X = pipeline.transform(train_X)\n",
    "\n",
    "    # Fit model over data\n",
    "    estimator = AgodaCancellationEstimator(threshold).fit(train_X, train_y)\n",
    "    pipeline.steps.append(('estimator', estimator))\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def export_test_data(pipeline: Pipeline, path=\"../datasets/test_set_week_1.csv\") -> NoReturn:\n",
    "    data = read_data_file(path)\n",
    "\n",
    "    # Store model predictions over test set\n",
    "    id1, id2, id3 = 209855253, 205843964, 212107536\n",
    "    evaluate_and_export(pipeline, data, f\"{id1}_{id2}_{id3}.csv\")\n",
    "\n",
    "pipeline = create_estimator_from_data()\n",
    "export_test_data(pipeline)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
